{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7114682,"sourceType":"datasetVersion","datasetId":4102913}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install -q -r requirements.txt","metadata":{"id":"BdTzdLxp3fo8","tags":[],"execution":{"iopub.status.busy":"2023-12-03T18:27:41.497347Z","iopub.execute_input":"2023-12-03T18:27:41.497643Z","iopub.status.idle":"2023-12-03T18:27:41.502563Z","shell.execute_reply.started":"2023-12-03T18:27:41.497616Z","shell.execute_reply":"2023-12-03T18:27:41.501567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\nimport matplotlib.pyplot as plt\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"ticks\", context=\"talk\")\nplt.style.use('dark_background')\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as func\nfrom torch.utils.data import DataLoader, Dataset\n\nimport transformers\nfrom transformers import AdamW, get_linear_schedule_with_warmup\n\nimport tokenizers\nfrom sklearn.metrics import mean_squared_error, roc_auc_score, roc_curve, auc","metadata":{"id":"oOCJEi843l_x","tags":[],"execution":{"iopub.status.busy":"2023-12-03T18:27:41.505095Z","iopub.execute_input":"2023-12-03T18:27:41.505780Z","iopub.status.idle":"2023-12-03T18:27:48.088079Z","shell.execute_reply.started":"2023-12-03T18:27:41.505744Z","shell.execute_reply":"2023-12-03T18:27:48.087275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INPUT_COL = 'Processed comment_text'\nTARGET_COL = ['toxic', 'severe_toxic','obscene', 'threat', 'insult','identity_hate']","metadata":{"id":"tzAJoJFZF7uJ","tags":[],"execution":{"iopub.status.busy":"2023-12-03T18:27:48.089907Z","iopub.execute_input":"2023-12-03T18:27:48.090655Z","iopub.status.idle":"2023-12-03T18:27:48.095483Z","shell.execute_reply.started":"2023-12-03T18:27:48.090620Z","shell.execute_reply":"2023-12-03T18:27:48.094252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/jigsaw-toxic-comments-preprocessed/train.csv', nrows=100)\ntest_data = pd.read_csv('/kaggle/input/jigsaw-toxic-comments-preprocessed/test.csv', nrows=100)","metadata":{"id":"GOtkU3ZS3uu5","tags":[],"execution":{"iopub.status.busy":"2023-12-03T18:27:48.096992Z","iopub.execute_input":"2023-12-03T18:27:48.097258Z","iopub.status.idle":"2023-12-03T18:27:48.137367Z","shell.execute_reply.started":"2023-12-03T18:27:48.097224Z","shell.execute_reply":"2023-12-03T18:27:48.136594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(test_data)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-03T18:27:48.139139Z","iopub.execute_input":"2023-12-03T18:27:48.139421Z","iopub.status.idle":"2023-12-03T18:27:48.145884Z","shell.execute_reply.started":"2023-12-03T18:27:48.139380Z","shell.execute_reply":"2023-12-03T18:27:48.145000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = train_data.dropna(subset=[INPUT_COL])\ntrain_data.head()","metadata":{"id":"FWGwtXGK4Dtw","outputId":"1bca4adb-2a40-4d5b-f206-981d7beb651b","tags":[],"execution":{"iopub.status.busy":"2023-12-03T18:27:48.146844Z","iopub.execute_input":"2023-12-03T18:27:48.147128Z","iopub.status.idle":"2023-12-03T18:27:48.182035Z","shell.execute_reply.started":"2023-12-03T18:27:48.147092Z","shell.execute_reply":"2023-12-03T18:27:48.181139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = test_data.dropna(subset=[INPUT_COL])\ntest_data.head()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-03T18:27:48.184283Z","iopub.execute_input":"2023-12-03T18:27:48.184533Z","iopub.status.idle":"2023-12-03T18:27:48.198837Z","shell.execute_reply.started":"2023-12-03T18:27:48.184510Z","shell.execute_reply":"2023-12-03T18:27:48.198008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')","metadata":{"id":"C3paF-tsGFFf","tags":[],"execution":{"iopub.status.busy":"2023-12-03T18:27:48.200143Z","iopub.execute_input":"2023-12-03T18:27:48.200525Z","iopub.status.idle":"2023-12-03T18:27:50.438200Z","shell.execute_reply.started":"2023-12-03T18:27:48.200501Z","shell.execute_reply":"2023-12-03T18:27:50.437309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sentence_len = []\n# for sentence in tqdm(train_data[INPUT_COL]):\n#     token_words = tokenizer.encode_plus(sentence)['input_ids']\n#     sentence_len.append(len(token_words))\n    \n# sns.displot(sentence_len, kde=True)\n# plt.xlim([0, 300])\n# plt.xlabel('Token count')","metadata":{"id":"GossWXV9C-rv","tags":[],"execution":{"iopub.status.busy":"2023-12-03T18:27:50.439357Z","iopub.execute_input":"2023-12-03T18:27:50.439637Z","iopub.status.idle":"2023-12-03T18:27:50.443508Z","shell.execute_reply.started":"2023-12-03T18:27:50.439612Z","shell.execute_reply":"2023-12-03T18:27:50.442645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Density measures the proportion of unique tokens in a text corpus.\n- Number of tokens refers to the total number of words or subword units in a text corpus.\n- Density can lead to more interpretable models, but may result in loss of information.\n- Number of tokens can preserve more information, but may lead to less interpretable models.\n- The choice between density and number of tokens depends on the specific task and the desired trade-off between model performance and interpretability.","metadata":{"id":"zGwqMO4MOUnA"}},{"cell_type":"code","source":"max_len = 200\nclass BertDataSet(Dataset):\n\n    def __init__(self, sentences, toxic_labels):\n        self.sentences = sentences.to_numpy()\n        self.targets = toxic_labels.to_numpy()\n\n    def __len__(self):\n        return len(self.sentences)\n\n    def __getitem__(self, idx):\n        bert_sentence = tokenizer.encode_plus(\n            self.sentences[idx],\n            add_special_tokens = True,\n            max_length = max_len,\n            pad_to_max_length = True,\n            truncation = True,\n            return_attention_mask = True\n        )\n\n        return {\n            'ids' : torch.tensor(bert_sentence['input_ids'], dtype = torch.long),\n            'mask' : torch.tensor(bert_sentence['attention_mask'], dtype = torch.long),\n            'toxic_label': torch.tensor(self.targets[idx], dtype = torch.float)\n        }\n","metadata":{"id":"M5GLMM8848UM","tags":[],"execution":{"iopub.status.busy":"2023-12-03T18:27:50.444776Z","iopub.execute_input":"2023-12-03T18:27:50.445619Z","iopub.status.idle":"2023-12-03T18:27:50.454952Z","shell.execute_reply.started":"2023-12-03T18:27:50.445585Z","shell.execute_reply":"2023-12-03T18:27:50.453929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = BertDataSet(train_data[INPUT_COL], train_data[TARGET_COL])\nvalid_dataset = BertDataSet(test_data[INPUT_COL], test_data[TARGET_COL])","metadata":{"id":"vTNJLCkeljf5","tags":[],"execution":{"iopub.status.busy":"2023-12-03T18:27:50.459460Z","iopub.execute_input":"2023-12-03T18:27:50.459749Z","iopub.status.idle":"2023-12-03T18:27:50.467863Z","shell.execute_reply.started":"2023-12-03T18:27:50.459724Z","shell.execute_reply":"2023-12-03T18:27:50.466924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_batch = 32\nvalid_batch = 32","metadata":{"id":"VN-euWyCGWTU","tags":[],"execution":{"iopub.status.busy":"2023-12-03T18:27:50.469280Z","iopub.execute_input":"2023-12-03T18:27:50.469643Z","iopub.status.idle":"2023-12-03T18:27:50.477102Z","shell.execute_reply.started":"2023-12-03T18:27:50.469609Z","shell.execute_reply":"2023-12-03T18:27:50.476306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size = train_batch, pin_memory = True, num_workers = 2, shuffle = True)\nvalid_dataloader = DataLoader(valid_dataset, batch_size = valid_batch, pin_memory = True, num_workers = 2, shuffle = False)","metadata":{"id":"zgozZVfSGZzq","tags":[],"execution":{"iopub.status.busy":"2023-12-03T18:27:50.478201Z","iopub.execute_input":"2023-12-03T18:27:50.478450Z","iopub.status.idle":"2023-12-03T18:27:50.487219Z","shell.execute_reply.started":"2023-12-03T18:27:50.478427Z","shell.execute_reply":"2023-12-03T18:27:50.486265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"id":"UE2dVnrrGdDn","outputId":"6de91758-8b35-4120-bb72-72c7cb262d25","tags":[],"execution":{"iopub.status.busy":"2023-12-03T18:27:50.488582Z","iopub.execute_input":"2023-12-03T18:27:50.488884Z","iopub.status.idle":"2023-12-03T18:27:50.564085Z","shell.execute_reply.started":"2023-12-03T18:27:50.488858Z","shell.execute_reply":"2023-12-03T18:27:50.563132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = transformers.BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = 6)\nmodel.to(device)\nmodel.train()","metadata":{"id":"UupPyGKYGc7m","outputId":"e2171b18-77ef-457a-eda4-dae4c16c8bc2","tags":[],"execution":{"iopub.status.busy":"2023-12-03T18:27:50.565255Z","iopub.execute_input":"2023-12-03T18:27:50.565602Z","iopub.status.idle":"2023-12-03T18:27:57.666732Z","shell.execute_reply.started":"2023-12-03T18:27:50.565569Z","shell.execute_reply":"2023-12-03T18:27:57.665822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for a in train_dataloader:\n    ids = a['ids'].to(device)\n    mask = a['mask'].to(device)\n    output = model(ids, mask)\n    break","metadata":{"id":"UiGsJLFBGh4z","tags":[],"execution":{"iopub.status.busy":"2023-12-03T18:27:57.667854Z","iopub.execute_input":"2023-12-03T18:27:57.668288Z","iopub.status.idle":"2023-12-03T18:28:01.072053Z","shell.execute_reply.started":"2023-12-03T18:27:57.668262Z","shell.execute_reply":"2023-12-03T18:28:01.070989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_probs = func.softmax(output['logits'], dim = 1)\ntorch.max(output_probs, dim = 1)","metadata":{"id":"Unlq-yjhGm7d","outputId":"e4e3021e-a0a8-42e3-9832-64f7d7c3456f","tags":[],"execution":{"iopub.status.busy":"2023-12-03T18:28:01.073322Z","iopub.execute_input":"2023-12-03T18:28:01.073645Z","iopub.status.idle":"2023-12-03T18:28:01.329014Z","shell.execute_reply.started":"2023-12-03T18:28:01.073614Z","shell.execute_reply":"2023-12-03T18:28:01.328146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 5\nLR = 2e-5 #Learning rate\noptimizer = AdamW(model.parameters(), LR, betas = (0.9, 0.999), weight_decay = 1e-2, correct_bias = False)","metadata":{"id":"XSAmeyG6GsEA","tags":[],"execution":{"iopub.status.busy":"2023-12-03T18:28:01.330336Z","iopub.execute_input":"2023-12-03T18:28:01.330628Z","iopub.status.idle":"2023-12-03T18:28:02.586860Z","shell.execute_reply.started":"2023-12-03T18:28:01.330594Z","shell.execute_reply":"2023-12-03T18:28:02.585871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_steps = int((len(train_data) * epochs)/train_batch)\nnum_steps = int(train_steps * 0.1)\nscheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)","metadata":{"id":"EdDwwxKRGwJ-","tags":[],"execution":{"iopub.status.busy":"2023-12-03T18:28:02.588296Z","iopub.execute_input":"2023-12-03T18:28:02.588690Z","iopub.status.idle":"2023-12-03T18:28:02.594123Z","shell.execute_reply.started":"2023-12-03T18:28:02.588648Z","shell.execute_reply":"2023-12-03T18:28:02.593232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le = []\nfor b in tqdm(range(epochs)):\n    for a in train_dataloader:\n        le.append(scheduler.get_last_lr())\n        scheduler.step()\nplt.plot(np.arange(len(le)), le)","metadata":{"id":"LBn_s5WmGwC2","outputId":"10efab94-2dca-4b99-b1fc-5a95a5f6f605","tags":[],"execution":{"iopub.status.busy":"2023-12-03T18:28:02.595297Z","iopub.execute_input":"2023-12-03T18:28:02.595545Z","iopub.status.idle":"2023-12-03T18:28:03.982411Z","shell.execute_reply.started":"2023-12-03T18:28:02.595520Z","shell.execute_reply":"2023-12-03T18:28:03.981352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_fn = nn.BCEWithLogitsLoss()\nloss_fn.to(device)\nscaler = torch.cuda.amp.GradScaler()","metadata":{"id":"1ZxKzk7VOrgm","outputId":"742a38a5-0948-4427-8900-c8cc646bdb44","tags":[],"execution":{"iopub.status.busy":"2023-12-03T18:28:03.983991Z","iopub.execute_input":"2023-12-03T18:28:03.984300Z","iopub.status.idle":"2023-12-03T18:28:03.989447Z","shell.execute_reply.started":"2023-12-03T18:28:03.984268Z","shell.execute_reply":"2023-12-03T18:28:03.988481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def training(train_dataloader, model, optimizer, scheduler):\n    model.train()\n    torch.backends.cudnn.benchmark = True\n    correct_predictions = 0\n\n    for a in train_dataloader:\n        losses = []\n        optimizer.zero_grad()\n\n        #allpreds = []\n        #alltargets = []\n\n        with torch.cuda.amp.autocast():\n\n            ids = a['ids'].to(device, non_blocking = True)\n            mask = a['mask'].to(device, non_blocking = True)\n\n            output = model(ids, mask) #This gives model as output, however we want the values at the output\n            output = output['logits'].squeeze(-1).to(torch.float32)\n\n            output_probs = torch.sigmoid(output)\n            preds = torch.where(output_probs > 0.5, 1, 0)\n\n            toxic_label = a['toxic_label'].to(device, non_blocking = True)\n            loss = loss_fn(output, toxic_label)\n\n            losses.append(loss.item())\n            #allpreds.append(output.detach().cpu().numpy())\n            #alltargets.append(toxic.detach().squeeze(-1).cpu().numpy())\n            correct_predictions += torch.sum(preds == toxic_label)\n\n        scaler.scale(loss).backward() #Multiplies (‘scales’) a tensor or list of tensors by the scale factor.\n                                      #Returns scaled outputs. If this instance of GradScaler is not enabled, outputs are returned unmodified.\n        scaler.step(optimizer) #Returns the return value of optimizer.step(*args, **kwargs).\n        scaler.update() #Updates the scale factor.If any optimizer steps were skipped the scale is multiplied by backoff_factor to reduce it.\n                        #If growth_interval unskipped iterations occurred consecutively, the scale is multiplied by growth_factor to increase it\n        scheduler.step() # Update learning rate schedule\n\n    losses = np.mean(losses)\n    corr_preds = correct_predictions.detach().cpu().numpy()\n    accuracy = corr_preds/(len(train_data)*6)\n\n    return losses, accuracy\n","metadata":{"id":"x0y60ynPOyCT","tags":[],"execution":{"iopub.status.busy":"2023-12-03T18:28:03.990763Z","iopub.execute_input":"2023-12-03T18:28:03.991376Z","iopub.status.idle":"2023-12-03T18:28:04.002139Z","shell.execute_reply.started":"2023-12-03T18:28:03.991342Z","shell.execute_reply":"2023-12-03T18:28:04.001219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validating(valid_dataloader, model):\n\n    model.eval()\n    correct_predictions = 0\n    all_output_probs = []\n\n    for a in valid_dataloader:\n        losses = []\n        ids = a['ids'].to(device, non_blocking = True)\n        mask = a['mask'].to(device, non_blocking = True)\n        output = model(ids, mask)\n        output = output['logits'].squeeze(-1).to(torch.float32)\n        output_probs = torch.sigmoid(output)\n        preds = torch.where(output_probs > 0.5, 1, 0)\n\n        toxic_label = a['toxic_label'].to(device, non_blocking = True)\n        loss = loss_fn(output, toxic_label)\n        losses.append(loss.item())\n        all_output_probs.extend(output_probs.detach().cpu().numpy())\n\n        correct_predictions += torch.sum(preds == toxic_label)\n        corr_preds = correct_predictions.detach().cpu().numpy()\n\n    losses = np.mean(losses)\n    corr_preds = correct_predictions.detach().cpu().numpy()\n    accuracy = corr_preds/(len(test_data)*6)\n\n    return losses, accuracy, all_output_probs\n","metadata":{"id":"LmULhO7fOz95","tags":[],"execution":{"iopub.status.busy":"2023-12-03T18:28:04.003269Z","iopub.execute_input":"2023-12-03T18:28:04.003607Z","iopub.status.idle":"2023-12-03T18:28:04.016889Z","shell.execute_reply.started":"2023-12-03T18:28:04.003575Z","shell.execute_reply":"2023-12-03T18:28:04.016006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nbest_score = 1000\ntrain_accs = []\nvalid_accs = []\ntrain_losses = []\nvalid_losses = []\n\nfor eboch in tqdm(range(epochs)):\n\n    train_loss, train_acc = training(train_dataloader, model, optimizer, scheduler)\n    valid_loss, valid_acc, valid_probs = validating(valid_dataloader, model)\n\n    print('train losses: %.4f' % train_loss, 'train accuracy: %.3f' % train_acc)\n    print('valid losses: %.4f' % valid_loss, 'valid accuracy: %.3f' % valid_acc)\n    train_losses.append(train_loss)\n    valid_losses.append(valid_loss)\n    train_accs.append(train_acc)\n    valid_accs.append(valid_acc)\n\n\n    if valid_loss < best_score:\n        best_score = valid_loss\n        print('Found a good model!')\n        state = {\n            'state_dict': model.state_dict(),\n            'optimizer_dict': optimizer.state_dict(),\n            'best_score': best_score\n        }\n        torch.save(state, 'best_model.pth')\n    else:\n        pass","metadata":{"id":"NXHEesyKO98x","outputId":"277cf1f0-36a4-44a1-85d8-a9526fb87205","tags":[],"execution":{"iopub.status.busy":"2023-12-03T18:28:04.017854Z","iopub.execute_input":"2023-12-03T18:28:04.018125Z","iopub.status.idle":"2023-12-03T18:28:07.389259Z","shell.execute_reply.started":"2023-12-03T18:28:04.018101Z","shell.execute_reply":"2023-12-03T18:28:07.388150Z"},"trusted":true},"execution_count":null,"outputs":[]}]}