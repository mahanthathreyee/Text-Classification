{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import roc_curve, accuracy_score, auc, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_TEST = Path('./data/jigsaw_toxic_comments/test.csv')\n",
    "\n",
    "MODEL_OUTPUT_DIR = Path('./data/model_outputs/full/')\n",
    "\n",
    "OUT_CNN = MODEL_OUTPUT_DIR / 'pred_cnn.csv'\n",
    "OUT_LSTM = MODEL_OUTPUT_DIR / 'pred_lstm.csv'\n",
    "OUT_LOGREG = MODEL_OUTPUT_DIR / 'pred_logreg.csv'\n",
    "OUT_NB_SVM = MODEL_OUTPUT_DIR / 'pred_nb_svm.csv'\n",
    "OUT_BERT = MODEL_OUTPUT_DIR / 'pred_bert.csv'\n",
    "OUT_ENSEM_AVG = MODEL_OUTPUT_DIR / 'pred_ensem_avg.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = pd.read_csv(IN_TEST)\n",
    "LABEL_COLS = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "MODEL_OUT_PROB = {\n",
    "    'CNN':                OUT_CNN, \n",
    "    'LSTM':               OUT_LSTM, \n",
    "    'LOGREG':             OUT_LOGREG, \n",
    "    'NB_SVM':             OUT_NB_SVM,\n",
    "    'BERT':               OUT_BERT,\n",
    "    'ENSEMBLE_AVERAGING': OUT_ENSEM_AVG\n",
    "}\n",
    "\n",
    "MODEL_OUT_PROB = {\n",
    "    k: pd.read_csv(v)[LABEL_COLS] for k, v in MODEL_OUT_PROB.items()\n",
    "}\n",
    "\n",
    "N_TE = len(TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in MODEL_OUT_PROB.values():\n",
    "    model.insert(0, 'id', TEST.id)\n",
    "\n",
    "TEST = pd.merge(left=pd.read_csv(IN_TEST), right=pd.read_csv(Path('./data/jigsaw_toxic_comments/test_labels.csv')), left_on='id', right_on='id')\n",
    "TEST = TEST[TEST.toxic != -1]\n",
    "\n",
    "MODEL_OUT_PROB = {\n",
    "    k: v[v.id.isin(TEST.id)] for k, v in MODEL_OUT_PROB.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>2.783060e-09</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>9.913385e-08</td>\n",
       "      <td>3.294415e-06</td>\n",
       "      <td>1.019644e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>0.061447</td>\n",
       "      <td>4.050740e-06</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>7.408154e-05</td>\n",
       "      <td>2.917345e-03</td>\n",
       "      <td>1.290226e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0002f87b16116a7f</td>\n",
       "      <td>0.016210</td>\n",
       "      <td>5.565348e-05</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>2.949872e-04</td>\n",
       "      <td>3.047977e-03</td>\n",
       "      <td>4.290054e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0003e1cccfd5a40a</td>\n",
       "      <td>0.007068</td>\n",
       "      <td>1.208248e-06</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>3.170063e-05</td>\n",
       "      <td>5.884999e-04</td>\n",
       "      <td>5.931168e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00059ace3e3e9a53</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>2.981097e-10</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>7.004811e-09</td>\n",
       "      <td>7.122055e-07</td>\n",
       "      <td>9.064986e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153150</th>\n",
       "      <td>fff8f64043129fa2</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>1.130469e-08</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>2.012253e-07</td>\n",
       "      <td>1.092839e-05</td>\n",
       "      <td>3.026531e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153151</th>\n",
       "      <td>fff9d70fe0722906</td>\n",
       "      <td>0.954490</td>\n",
       "      <td>5.183419e-03</td>\n",
       "      <td>0.518844</td>\n",
       "      <td>7.832063e-04</td>\n",
       "      <td>5.646287e-01</td>\n",
       "      <td>7.741437e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153154</th>\n",
       "      <td>fffa8a11c4378854</td>\n",
       "      <td>0.942306</td>\n",
       "      <td>4.343872e-02</td>\n",
       "      <td>0.256488</td>\n",
       "      <td>8.719553e-02</td>\n",
       "      <td>5.757344e-01</td>\n",
       "      <td>2.896482e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153155</th>\n",
       "      <td>fffac2a094c8e0e2</td>\n",
       "      <td>0.989430</td>\n",
       "      <td>1.584197e-01</td>\n",
       "      <td>0.913899</td>\n",
       "      <td>2.562255e-02</td>\n",
       "      <td>7.776085e-01</td>\n",
       "      <td>8.603556e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153156</th>\n",
       "      <td>fffb5451268fb5ba</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>6.372409e-09</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>1.185512e-07</td>\n",
       "      <td>1.013566e-05</td>\n",
       "      <td>1.292576e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63978 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id     toxic  severe_toxic   obscene        threat  \\\n",
       "5       0001ea8717f6de06  0.000058  2.783060e-09  0.000015  9.913385e-08   \n",
       "7       000247e83dcc1211  0.061447  4.050740e-06  0.001258  7.408154e-05   \n",
       "11      0002f87b16116a7f  0.016210  5.565348e-05  0.003242  2.949872e-04   \n",
       "13      0003e1cccfd5a40a  0.007068  1.208248e-06  0.000634  3.170063e-05   \n",
       "14      00059ace3e3e9a53  0.000009  2.981097e-10  0.000004  7.004811e-09   \n",
       "...                  ...       ...           ...       ...           ...   \n",
       "153150  fff8f64043129fa2  0.000119  1.130469e-08  0.000036  2.012253e-07   \n",
       "153151  fff9d70fe0722906  0.954490  5.183419e-03  0.518844  7.832063e-04   \n",
       "153154  fffa8a11c4378854  0.942306  4.343872e-02  0.256488  8.719553e-02   \n",
       "153155  fffac2a094c8e0e2  0.989430  1.584197e-01  0.913899  2.562255e-02   \n",
       "153156  fffb5451268fb5ba  0.000163  6.372409e-09  0.000024  1.185512e-07   \n",
       "\n",
       "              insult  identity_hate  \n",
       "5       3.294415e-06   1.019644e-07  \n",
       "7       2.917345e-03   1.290226e-04  \n",
       "11      3.047977e-03   4.290054e-04  \n",
       "13      5.884999e-04   5.931168e-05  \n",
       "14      7.122055e-07   9.064986e-09  \n",
       "...              ...            ...  \n",
       "153150  1.092839e-05   3.026531e-07  \n",
       "153151  5.646287e-01   7.741437e-03  \n",
       "153154  5.757344e-01   2.896482e-01  \n",
       "153155  7.776085e-01   8.603556e-02  \n",
       "153156  1.013566e-05   1.292576e-07  \n",
       "\n",
       "[63978 rows x 7 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = MODEL_OUT_PROB['CNN']\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maganthseetharaman/Desktop/COMPSCI 273A/project/env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_scores = defaultdict(None)\n",
    "\n",
    "for model in MODEL_OUT_PROB:\n",
    "    scores = defaultdict(list)\n",
    "    y_pred_prob = MODEL_OUT_PROB[model]\n",
    "\n",
    "    for col in LABEL_COLS:\n",
    "        y_pred = y_pred_prob[col].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "        fpr, tpr, _ = roc_curve(TEST[col].values, y_pred_prob[col])\n",
    "        scores['train_accuracy'] += accuracy_score(y_pred, TEST[col].values),\n",
    "        scores['test_accuracy'] += accuracy_score(y_pred, TEST[col].values),\n",
    "        scores['auc_score'] += auc(fpr, tpr),\n",
    "        scores['f1_score'] += f1_score(TEST[col].values, y_pred, average=\"weighted\"),\n",
    "        scores['precision'] += precision_score(TEST[col].values, y_pred, average=\"weighted\"),\n",
    "        scores['recall'] += recall_score(TEST[col].values, y_pred, average=\"weighted\"),\n",
    "\n",
    "    scores = pd.DataFrame.from_dict(scores)\n",
    "    scores['label']= LABEL_COLS\n",
    "    scores.set_index('label', inplace=True)\n",
    "    model_scores[model] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"scores\":{\n",
      "    \"CNN\":\"{\\n  \\\"train_accuracy\\\":{\\n    \\\"toxic\\\":0.9113132639,\\n    \\\"severe_toxic\\\":0.9922629654,\\n    \\\"obscene\\\":0.9555003282,\\n    \\\"threat\\\":0.9967019913,\\n    \\\"insult\\\":0.9494201132,\\n    \\\"identity_hate\\\":0.9897933665\\n  },\\n  \\\"test_accuracy\\\":{\\n    \\\"toxic\\\":0.9113132639,\\n    \\\"severe_toxic\\\":0.9922629654,\\n    \\\"obscene\\\":0.9555003282,\\n    \\\"threat\\\":0.9967019913,\\n    \\\"insult\\\":0.9494201132,\\n    \\\"identity_hate\\\":0.9897933665\\n  },\\n  \\\"auc_score\\\":{\\n    \\\"toxic\\\":0.9444422262,\\n    \\\"severe_toxic\\\":0.9806841113,\\n    \\\"obscene\\\":0.9561881565,\\n    \\\"threat\\\":0.9475504237,\\n    \\\"insult\\\":0.9475378204,\\n    \\\"identity_hate\\\":0.949589927\\n  },\\n  \\\"f1_score\\\":{\\n    \\\"toxic\\\":0.9193164848,\\n    \\\"severe_toxic\\\":0.9925845109,\\n    \\\"obscene\\\":0.9572671936,\\n    \\\"threat\\\":0.9950557107,\\n    \\\"insult\\\":0.9521981373,\\n    \\\"identity_hate\\\":0.9862379036\\n  },\\n  \\\"precision\\\":{\\n    \\\"toxic\\\":0.9342240867,\\n    \\\"severe_toxic\\\":0.992937487,\\n    \\\"obscene\\\":0.9596397255,\\n    \\\"threat\\\":0.9934148595,\\n    \\\"insult\\\":0.9559560765,\\n    \\\"identity_hate\\\":0.9874602466\\n  },\\n  \\\"recall\\\":{\\n    \\\"toxic\\\":0.9113132639,\\n    \\\"severe_toxic\\\":0.9922629654,\\n    \\\"obscene\\\":0.9555003282,\\n    \\\"threat\\\":0.9967019913,\\n    \\\"insult\\\":0.9494201132,\\n    \\\"identity_hate\\\":0.9897933665\\n  }\\n}\",\n",
      "    \"LSTM\":\"{\\n  \\\"train_accuracy\\\":{\\n    \\\"toxic\\\":0.9131732783,\\n    \\\"severe_toxic\\\":0.9912157304,\\n    \\\"obscene\\\":0.9593610304,\\n    \\\"threat\\\":0.996858295,\\n    \\\"insult\\\":0.9612523055,\\n    \\\"identity_hate\\\":0.9915595986\\n  },\\n  \\\"test_accuracy\\\":{\\n    \\\"toxic\\\":0.9131732783,\\n    \\\"severe_toxic\\\":0.9912157304,\\n    \\\"obscene\\\":0.9593610304,\\n    \\\"threat\\\":0.996858295,\\n    \\\"insult\\\":0.9612523055,\\n    \\\"identity_hate\\\":0.9915595986\\n  },\\n  \\\"auc_score\\\":{\\n    \\\"toxic\\\":0.9583635726,\\n    \\\"severe_toxic\\\":0.9861194384,\\n    \\\"obscene\\\":0.970114134,\\n    \\\"threat\\\":0.9796054385,\\n    \\\"insult\\\":0.9657341548,\\n    \\\"identity_hate\\\":0.9728348462\\n  },\\n  \\\"f1_score\\\":{\\n    \\\"toxic\\\":0.921751257,\\n    \\\"severe_toxic\\\":0.9920821112,\\n    \\\"obscene\\\":0.9608952773,\\n    \\\"threat\\\":0.9960377916,\\n    \\\"insult\\\":0.9615071337,\\n    \\\"identity_hate\\\":0.9905990448\\n  },\\n  \\\"precision\\\":{\\n    \\\"toxic\\\":0.9390444064,\\n    \\\"severe_toxic\\\":0.9931347843,\\n    \\\"obscene\\\":0.9629981043,\\n    \\\"threat\\\":0.9959029251,\\n    \\\"insult\\\":0.961776578,\\n    \\\"identity_hate\\\":0.9903088372\\n  },\\n  \\\"recall\\\":{\\n    \\\"toxic\\\":0.9131732783,\\n    \\\"severe_toxic\\\":0.9912157304,\\n    \\\"obscene\\\":0.9593610304,\\n    \\\"threat\\\":0.996858295,\\n    \\\"insult\\\":0.9612523055,\\n    \\\"identity_hate\\\":0.9915595986\\n  }\\n}\",\n",
      "    \"LOGREG\":\"{\\n  \\\"train_accuracy\\\":{\\n    \\\"toxic\\\":0.8829285067,\\n    \\\"severe_toxic\\\":0.9738503861,\\n    \\\"obscene\\\":0.9417612304,\\n    \\\"threat\\\":0.9923411173,\\n    \\\"insult\\\":0.9347119322,\\n    \\\"identity_hate\\\":0.9749914033\\n  },\\n  \\\"test_accuracy\\\":{\\n    \\\"toxic\\\":0.8829285067,\\n    \\\"severe_toxic\\\":0.9738503861,\\n    \\\"obscene\\\":0.9417612304,\\n    \\\"threat\\\":0.9923411173,\\n    \\\"insult\\\":0.9347119322,\\n    \\\"identity_hate\\\":0.9749914033\\n  },\\n  \\\"auc_score\\\":{\\n    \\\"toxic\\\":0.9637209552,\\n    \\\"severe_toxic\\\":0.9860665368,\\n    \\\"obscene\\\":0.9787011727,\\n    \\\"threat\\\":0.9925605936,\\n    \\\"insult\\\":0.9731709425,\\n    \\\"identity_hate\\\":0.985776059\\n  },\\n  \\\"f1_score\\\":{\\n    \\\"toxic\\\":0.8998475033,\\n    \\\"severe_toxic\\\":0.9825742347,\\n    \\\"obscene\\\":0.9491743235,\\n    \\\"threat\\\":0.9942204685,\\n    \\\"insult\\\":0.9443479722,\\n    \\\"identity_hate\\\":0.9810032341\\n  },\\n  \\\"precision\\\":{\\n    \\\"toxic\\\":0.9385966199,\\n    \\\"severe_toxic\\\":0.9942556189,\\n    \\\"obscene\\\":0.9638464004,\\n    \\\"threat\\\":0.9969989683,\\n    \\\"insult\\\":0.9627163494,\\n    \\\"identity_hate\\\":0.9902977751\\n  },\\n  \\\"recall\\\":{\\n    \\\"toxic\\\":0.8829285067,\\n    \\\"severe_toxic\\\":0.9738503861,\\n    \\\"obscene\\\":0.9417612304,\\n    \\\"threat\\\":0.9923411173,\\n    \\\"insult\\\":0.9347119322,\\n    \\\"identity_hate\\\":0.9749914033\\n  }\\n}\",\n",
      "    \"NB_SVM\":\"{\\n  \\\"train_accuracy\\\":{\\n    \\\"toxic\\\":0.9335240239,\\n    \\\"severe_toxic\\\":0.9926537247,\\n    \\\"obscene\\\":0.96647285,\\n    \\\"threat\\\":0.9971552721,\\n    \\\"insult\\\":0.965550658,\\n    \\\"identity_hate\\\":0.9909031229\\n  },\\n  \\\"test_accuracy\\\":{\\n    \\\"toxic\\\":0.9335240239,\\n    \\\"severe_toxic\\\":0.9926537247,\\n    \\\"obscene\\\":0.96647285,\\n    \\\"threat\\\":0.9971552721,\\n    \\\"insult\\\":0.965550658,\\n    \\\"identity_hate\\\":0.9909031229\\n  },\\n  \\\"auc_score\\\":{\\n    \\\"toxic\\\":0.9663122906,\\n    \\\"severe_toxic\\\":0.9792195085,\\n    \\\"obscene\\\":0.9757057766,\\n    \\\"threat\\\":0.9918513691,\\n    \\\"insult\\\":0.9702208867,\\n    \\\"identity_hate\\\":0.9746645006\\n  },\\n  \\\"f1_score\\\":{\\n    \\\"toxic\\\":0.9368048857,\\n    \\\"severe_toxic\\\":0.9926134803,\\n    \\\"obscene\\\":0.9659222117,\\n    \\\"threat\\\":0.9967597596,\\n    \\\"insult\\\":0.9629131425,\\n    \\\"identity_hate\\\":0.989128416\\n  },\\n  \\\"precision\\\":{\\n    \\\"toxic\\\":0.9420761587,\\n    \\\"severe_toxic\\\":0.9925737351,\\n    \\\"obscene\\\":0.9654778779,\\n    \\\"threat\\\":0.9966145778,\\n    \\\"insult\\\":0.9621727378,\\n    \\\"identity_hate\\\":0.9891274628\\n  },\\n  \\\"recall\\\":{\\n    \\\"toxic\\\":0.9335240239,\\n    \\\"severe_toxic\\\":0.9926537247,\\n    \\\"obscene\\\":0.96647285,\\n    \\\"threat\\\":0.9971552721,\\n    \\\"insult\\\":0.965550658,\\n    \\\"identity_hate\\\":0.9909031229\\n  }\\n}\",\n",
      "    \"BERT\":\"{\\n  \\\"train_accuracy\\\":{\\n    \\\"toxic\\\":0.923051674,\\n    \\\"severe_toxic\\\":0.9928725499,\\n    \\\"obscene\\\":0.9599549845,\\n    \\\"threat\\\":0.9973897277,\\n    \\\"insult\\\":0.9658320048,\\n    \\\"identity_hate\\\":0.9925599425\\n  },\\n  \\\"test_accuracy\\\":{\\n    \\\"toxic\\\":0.923051674,\\n    \\\"severe_toxic\\\":0.9928725499,\\n    \\\"obscene\\\":0.9599549845,\\n    \\\"threat\\\":0.9973897277,\\n    \\\"insult\\\":0.9658320048,\\n    \\\"identity_hate\\\":0.9925599425\\n  },\\n  \\\"auc_score\\\":{\\n    \\\"toxic\\\":0.9749000987,\\n    \\\"severe_toxic\\\":0.9908903259,\\n    \\\"obscene\\\":0.9822956764,\\n    \\\"threat\\\":0.9957299,\\n    \\\"insult\\\":0.9818711906,\\n    \\\"identity_hate\\\":0.9921550244\\n  },\\n  \\\"f1_score\\\":{\\n    \\\"toxic\\\":0.9309024672,\\n    \\\"severe_toxic\\\":0.9932895683,\\n    \\\"obscene\\\":0.962648322,\\n    \\\"threat\\\":0.9971353219,\\n    \\\"insult\\\":0.9672273805,\\n    \\\"identity_hate\\\":0.9921068541\\n  },\\n  \\\"precision\\\":{\\n    \\\"toxic\\\":0.9486666344,\\n    \\\"severe_toxic\\\":0.9937807105,\\n    \\\"obscene\\\":0.9672876323,\\n    \\\"threat\\\":0.9970195643,\\n    \\\"insult\\\":0.969258153,\\n    \\\"identity_hate\\\":0.9918704114\\n  },\\n  \\\"recall\\\":{\\n    \\\"toxic\\\":0.923051674,\\n    \\\"severe_toxic\\\":0.9928725499,\\n    \\\"obscene\\\":0.9599549845,\\n    \\\"threat\\\":0.9973897277,\\n    \\\"insult\\\":0.9658320048,\\n    \\\"identity_hate\\\":0.9925599425\\n  }\\n}\",\n",
      "    \"ENSEMBLE_AVERAGING\":\"{\\n  \\\"train_accuracy\\\":{\\n    \\\"toxic\\\":0.9209884648,\\n    \\\"severe_toxic\\\":0.9903404295,\\n    \\\"obscene\\\":0.9607677639,\\n    \\\"threat\\\":0.997233424,\\n    \\\"insult\\\":0.9637687955,\\n    \\\"identity_hate\\\":0.992622464\\n  },\\n  \\\"test_accuracy\\\":{\\n    \\\"toxic\\\":0.9209884648,\\n    \\\"severe_toxic\\\":0.9903404295,\\n    \\\"obscene\\\":0.9607677639,\\n    \\\"threat\\\":0.997233424,\\n    \\\"insult\\\":0.9637687955,\\n    \\\"identity_hate\\\":0.992622464\\n  },\\n  \\\"auc_score\\\":{\\n    \\\"toxic\\\":0.9716825526,\\n    \\\"severe_toxic\\\":0.9897681056,\\n    \\\"obscene\\\":0.9816215484,\\n    \\\"threat\\\":0.9939297667,\\n    \\\"insult\\\":0.9790863354,\\n    \\\"identity_hate\\\":0.9903919806\\n  },\\n  \\\"f1_score\\\":{\\n    \\\"toxic\\\":0.9288750869,\\n    \\\"severe_toxic\\\":0.9918865382,\\n    \\\"obscene\\\":0.9630829162,\\n    \\\"threat\\\":0.9967040535,\\n    \\\"insult\\\":0.9652811779,\\n    \\\"identity_hate\\\":0.9920668618\\n  },\\n  \\\"precision\\\":{\\n    \\\"toxic\\\":0.9460559484,\\n    \\\"severe_toxic\\\":0.9940217079,\\n    \\\"obscene\\\":0.9668773973,\\n    \\\"threat\\\":0.9966539873,\\n    \\\"insult\\\":0.9674435058,\\n    \\\"identity_hate\\\":0.9918414322\\n  },\\n  \\\"recall\\\":{\\n    \\\"toxic\\\":0.9209884648,\\n    \\\"severe_toxic\\\":0.9903404295,\\n    \\\"obscene\\\":0.9607677639,\\n    \\\"threat\\\":0.997233424,\\n    \\\"insult\\\":0.9637687955,\\n    \\\"identity_hate\\\":0.992622464\\n  }\\n}\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(\n",
    "    [(k, v.to_json(indent=2)) for k, v in model_scores.items()],\n",
    "    columns=['model', 'scores']\n",
    ").set_index('model').to_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
